{"run_id":"1765453151-528265000","line":649,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"aggregation_with_high_cardinality_factor","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":649,"expression":"plan"},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n│       ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n│         AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n│           [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n└──────────────────────────────────────────────────\n  ┌───── Stage 1 ── Tasks: t0:[p0..p3] t1:[p0..p3] t2:[p0..p3] \n  │ CoalesceBatchesExec: target_batch_size=8192\n  │   RepartitionExec: partitioning=Hash([RainToday@0], 4), input_partitions=1\n  │     AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │       PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n  │         DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n  └──────────────────────────────────────────────────"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n│       ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n│         AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n│           [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n└──────────────────────────────────────────────────\n  ┌───── Stage 1 ── Tasks: t0:[p0..p3] t1:[p0..p3] t2:[p0..p3] \n  │ CoalesceBatchesExec: target_batch_size=8192\n  │   RepartitionExec: partitioning=Hash([RainToday@0], 4), input_partitions=4\n  │     RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n  │       AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │         PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n  │           DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n  └──────────────────────────────────────────────────"}}
{"run_id":"1765453151-528265000","line":560,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"aggregation","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":560,"expression":"plan"},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n  │   ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n  │     AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │       [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0], 8), input_partitions=1\n    │     AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n    │       PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │         DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n    └──────────────────────────────────────────────────"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n  │   ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n  │     AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │       [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0], 8), input_partitions=4\n    │     RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n    │       AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n    │         PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │           DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n    └──────────────────────────────────────────────────"}}
{"run_id":"1765453151-528265000","line":735,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"left_join","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":735,"expression":"plan"},"snapshot":"HashJoinExec: mode=CollectLeft, join_type=Left, on=[(RainToday@1, RainToday@1)], projection=[MinTemp@0, MaxTemp@2]\n  CoalescePartitionsExec\n    DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MinTemp, RainToday], file_type=parquet\n  DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MaxTemp, RainToday], file_type=parquet"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"CoalesceBatchesExec: target_batch_size=8192\n  HashJoinExec: mode=CollectLeft, join_type=Left, on=[(RainToday@1, RainToday@1)], projection=[MinTemp@0, MaxTemp@2]\n    CoalescePartitionsExec\n      DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MinTemp, RainToday], file_type=parquet\n    DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MaxTemp, RainToday], file_type=parquet"}}
{"run_id":"1765453151-528265000","line":680,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"aggregation_with_a_lot_of_files_per_task","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":680,"expression":"plan"},"snapshot":"ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n  SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n    SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n      ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n        AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n          CoalesceBatchesExec: target_batch_size=8192\n            RepartitionExec: partitioning=Hash([RainToday@0], 4), input_partitions=3\n              AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n                DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n  SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n    SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n      ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n        AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n          CoalesceBatchesExec: target_batch_size=8192\n            RepartitionExec: partitioning=Hash([RainToday@0], 4), input_partitions=4\n              RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=3\n                AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n                  DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet"}}
{"run_id":"1765453151-528265000","line":703,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"aggregation_with_partitions_per_task","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":703,"expression":"plan"},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n  │   ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n  │     AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │       [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0], 8), input_partitions=1\n    │     AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n    │       PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │         DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n    └──────────────────────────────────────────────────"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n  │   ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n  │     AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │       [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0], 8), input_partitions=4\n    │     RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n    │       AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n    │         PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │           DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n    └──────────────────────────────────────────────────"}}
{"run_id":"1765453151-528265000","line":872,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"show_columns","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":872,"expression":"plan"},"snapshot":"CoalescePartitionsExec\n  ProjectionExec: expr=[table_catalog@0 as table_catalog, table_schema@1 as table_schema, table_name@2 as table_name, column_name@3 as column_name, data_type@5 as data_type, is_nullable@4 as is_nullable]\n    FilterExec: table_name@2 = weather\n      RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n        StreamingTableExec: partition_sizes=1, projection=[table_catalog, table_schema, table_name, column_name, is_nullable, data_type]"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"CoalescePartitionsExec\n  ProjectionExec: expr=[table_catalog@0 as table_catalog, table_schema@1 as table_schema, table_name@2 as table_name, column_name@3 as column_name, data_type@5 as data_type, is_nullable@4 as is_nullable]\n    CoalesceBatchesExec: target_batch_size=8192\n      FilterExec: table_name@2 = weather\n        RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n          StreamingTableExec: partition_sizes=1, projection=[table_catalog, table_schema, table_name, column_name, is_nullable, data_type]"}}
{"run_id":"1765453151-528265000","line":843,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"distinct","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":843,"expression":"plan"},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ CoalescePartitionsExec\n│   [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday, WindGustDir@1 as WindGustDir], aggr=[]\n  │   [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0, WindGustDir@1], 8), input_partitions=1\n    │     AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday, WindGustDir@1 as WindGustDir], aggr=[]\n    │       PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │         DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday, WindGustDir], file_type=parquet\n    └──────────────────────────────────────────────────"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ CoalescePartitionsExec\n│   [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday, WindGustDir@1 as WindGustDir], aggr=[]\n  │   [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0, WindGustDir@1], 8), input_partitions=4\n    │     RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n    │       AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday, WindGustDir@1 as WindGustDir], aggr=[]\n    │         PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │           DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday, WindGustDir], file_type=parquet\n    └──────────────────────────────────────────────────"}}
{"run_id":"1765453151-528265000","line":592,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"aggregation_with_fewer_workers_than_files","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":592,"expression":"plan"},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n  │   ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n  │     AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │       [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=2\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0], 8), input_partitions=2\n    │     AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n    │       PartitionIsolatorExec: t0:[p0,p1,__] t1:[__,__,p0] \n    │         DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n    └──────────────────────────────────────────────────"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n│   SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n│     [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n  │   ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n  │     AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n  │       [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=2\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainToday@0], 8), input_partitions=4\n    │     RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=2\n    │       AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n    │         PartitionIsolatorExec: t0:[p0,p1,__] t1:[__,__,p0] \n    │           DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet\n    └──────────────────────────────────────────────────"}}
{"run_id":"1765453151-528265000","line":624,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"aggregation_with_0_workers","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":624,"expression":"plan"},"snapshot":"ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n  SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n    SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n      ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n        AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n          CoalesceBatchesExec: target_batch_size=8192\n            RepartitionExec: partitioning=Hash([RainToday@0], 4), input_partitions=3\n              AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n                DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"ProjectionExec: expr=[count(*)@0 as count(*), RainToday@1 as RainToday]\n  SortPreservingMergeExec: [count(Int64(1))@2 ASC NULLS LAST]\n    SortExec: expr=[count(*)@0 ASC NULLS LAST], preserve_partitioning=[true]\n      ProjectionExec: expr=[count(Int64(1))@1 as count(*), RainToday@0 as RainToday, count(Int64(1))@1 as count(Int64(1))]\n        AggregateExec: mode=FinalPartitioned, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n          CoalesceBatchesExec: target_batch_size=8192\n            RepartitionExec: partitioning=Hash([RainToday@0], 4), input_partitions=4\n              RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=3\n                AggregateExec: mode=Partial, gby=[RainToday@0 as RainToday], aggr=[count(Int64(1))]\n                  DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[RainToday], file_type=parquet"}}
{"run_id":"1765453151-528265000","line":773,"new":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","snapshot_name":"left_join_distributed","metadata":{"source":"src/distributed_planner/distributed_physical_optimizer_rule.rs","assertion_line":773,"expression":"plan"},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ CoalescePartitionsExec\n│   HashJoinExec: mode=CollectLeft, join_type=Left, on=[(RainTomorrow@1, RainTomorrow@1)], projection=[MinTemp@0, MaxTemp@2]\n│     CoalescePartitionsExec\n│       [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n│     ProjectionExec: expr=[avg(weather.MaxTemp)@1 as MaxTemp, RainTomorrow@0 as RainTomorrow]\n│       AggregateExec: mode=FinalPartitioned, gby=[RainTomorrow@0 as RainTomorrow], aggr=[avg(weather.MaxTemp)]\n│         [Stage 3] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ ProjectionExec: expr=[avg(weather.MinTemp)@1 as MinTemp, RainTomorrow@0 as RainTomorrow]\n  │   AggregateExec: mode=FinalPartitioned, gby=[RainTomorrow@0 as RainTomorrow], aggr=[avg(weather.MinTemp)]\n  │     [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainTomorrow@0], 8), input_partitions=4\n    │     AggregateExec: mode=Partial, gby=[RainTomorrow@1 as RainTomorrow], aggr=[avg(weather.MinTemp)]\n    │       FilterExec: RainToday@1 = yes, projection=[MinTemp@0, RainTomorrow@2]\n    │         RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n    │           PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │             DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MinTemp, RainToday, RainTomorrow], file_type=parquet, predicate=RainToday@19 = yes, pruning_predicate=RainToday_null_count@2 != row_count@3 AND RainToday_min@0 <= yes AND yes <= RainToday_max@1, required_guarantees=[RainToday in (yes)]\n    └──────────────────────────────────────────────────\n  ┌───── Stage 3 ── Tasks: t0:[p0..p3] t1:[p0..p3] t2:[p0..p3] \n  │ CoalesceBatchesExec: target_batch_size=8192\n  │   RepartitionExec: partitioning=Hash([RainTomorrow@0], 4), input_partitions=4\n  │     AggregateExec: mode=Partial, gby=[RainTomorrow@1 as RainTomorrow], aggr=[avg(weather.MaxTemp)]\n  │       FilterExec: RainToday@1 = no, projection=[MaxTemp@0, RainTomorrow@2]\n  │         RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n  │           PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n  │             DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MaxTemp, RainToday, RainTomorrow], file_type=parquet, predicate=RainToday@19 = no, pruning_predicate=RainToday_null_count@2 != row_count@3 AND RainToday_min@0 <= no AND no <= RainToday_max@1, required_guarantees=[RainToday in (no)]\n  └──────────────────────────────────────────────────"},"old":{"module_name":"datafusion_distributed__distributed_planner__distributed_physical_optimizer_rule__tests","metadata":{},"snapshot":"┌───── DistributedExec ── Tasks: t0:[p0] \n│ CoalescePartitionsExec\n│   CoalesceBatchesExec: target_batch_size=8192\n│     HashJoinExec: mode=CollectLeft, join_type=Left, on=[(RainTomorrow@1, RainTomorrow@1)], projection=[MinTemp@0, MaxTemp@2]\n│       CoalescePartitionsExec\n│         [Stage 2] => NetworkCoalesceExec: output_partitions=8, input_tasks=2\n│       ProjectionExec: expr=[avg(weather.MaxTemp)@1 as MaxTemp, RainTomorrow@0 as RainTomorrow]\n│         AggregateExec: mode=FinalPartitioned, gby=[RainTomorrow@0 as RainTomorrow], aggr=[avg(weather.MaxTemp)]\n│           [Stage 3] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n└──────────────────────────────────────────────────\n  ┌───── Stage 2 ── Tasks: t0:[p0..p3] t1:[p0..p3] \n  │ ProjectionExec: expr=[avg(weather.MinTemp)@1 as MinTemp, RainTomorrow@0 as RainTomorrow]\n  │   AggregateExec: mode=FinalPartitioned, gby=[RainTomorrow@0 as RainTomorrow], aggr=[avg(weather.MinTemp)]\n  │     [Stage 1] => NetworkShuffleExec: output_partitions=4, input_tasks=3\n  └──────────────────────────────────────────────────\n    ┌───── Stage 1 ── Tasks: t0:[p0..p7] t1:[p0..p7] t2:[p0..p7] \n    │ CoalesceBatchesExec: target_batch_size=8192\n    │   RepartitionExec: partitioning=Hash([RainTomorrow@0], 8), input_partitions=4\n    │     AggregateExec: mode=Partial, gby=[RainTomorrow@1 as RainTomorrow], aggr=[avg(weather.MinTemp)]\n    │       CoalesceBatchesExec: target_batch_size=8192\n    │         FilterExec: RainToday@1 = yes, projection=[MinTemp@0, RainTomorrow@2]\n    │           RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n    │             PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n    │               DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MinTemp, RainToday, RainTomorrow], file_type=parquet, predicate=RainToday@1 = yes, pruning_predicate=RainToday_null_count@2 != row_count@3 AND RainToday_min@0 <= yes AND yes <= RainToday_max@1, required_guarantees=[RainToday in (yes)]\n    └──────────────────────────────────────────────────\n  ┌───── Stage 3 ── Tasks: t0:[p0..p3] t1:[p0..p3] t2:[p0..p3] \n  │ CoalesceBatchesExec: target_batch_size=8192\n  │   RepartitionExec: partitioning=Hash([RainTomorrow@0], 4), input_partitions=4\n  │     AggregateExec: mode=Partial, gby=[RainTomorrow@1 as RainTomorrow], aggr=[avg(weather.MaxTemp)]\n  │       CoalesceBatchesExec: target_batch_size=8192\n  │         FilterExec: RainToday@1 = no, projection=[MaxTemp@0, RainTomorrow@2]\n  │           RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1\n  │             PartitionIsolatorExec: t0:[p0,__,__] t1:[__,p0,__] t2:[__,__,p0] \n  │               DataSourceExec: file_groups={3 groups: [[/testdata/weather/result-000000.parquet], [/testdata/weather/result-000001.parquet], [/testdata/weather/result-000002.parquet]]}, projection=[MaxTemp, RainToday, RainTomorrow], file_type=parquet, predicate=RainToday@1 = no, pruning_predicate=RainToday_null_count@2 != row_count@3 AND RainToday_min@0 <= no AND no <= RainToday_max@1, required_guarantees=[RainToday in (no)]\n  └──────────────────────────────────────────────────"}}
